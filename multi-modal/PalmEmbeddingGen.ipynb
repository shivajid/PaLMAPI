{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f3537ea-8f91-4efe-b33a-38bfb2efbc8f",
   "metadata": {},
   "source": [
    "# Text Embedding using Palm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "899e49d8-673e-4c9e-9d06-c1ed6604db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import vertexai\n",
    "from vertexai.preview.language_models import TextGenerationModel,TextEmbeddingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddf3685b-b0bd-478b-83b8-7c8f73911b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID= \"demogct2022\"\n",
    "Region = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8519c2a6-b1bf-45da-a75a-3af5cce118d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexai.init(project=PROJECT_ID,location=Region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02de8732-e718-4166-8182-d41800dd5a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29859b40-a38a-4b95-b9f4-509e03ef894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_embeddings( wikipedia_strings):\n",
    " index = 0\n",
    " allembeddings = []\n",
    " for i in range(5,len (wikipedia_strings)+1,5):\n",
    "   print(i)\n",
    "   embedarr = model.get_embeddings(wikipedia_strings[index:i] )\n",
    "   allembeddings.append(embedarr)\n",
    "   index = i\n",
    " return allembeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "371ab3d5-b9c8-468c-82ab-6a9add62ef63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "236e28b6-c374-42c8-ac9e-8f594ab9db54",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"metadata_list_txt_uptd.jsonl\", \"rb\") as f:\n",
    "    metadata_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bba74ad8-7594-4a28-99e6-81ab6cb99870",
   "metadata": {},
   "outputs": [],
   "source": [
    "promptlist = [text[\"prompts\"] for text in metadata_df]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e89006ed-712e-4933-9a83-e032d0616489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114350"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(promptlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3decc7ce-368c-4e00-9613-e52387f868c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def gen_embeddings( promptlist):\n",
    " index = 0\n",
    " allembeddings = []\n",
    " errors = []\n",
    " for i in range(5,len (promptlist)+1,5):\n",
    "   print(i)\n",
    "   try:\n",
    "    embedarr = model.get_embeddings(promptlist[index:i] )\n",
    "    allembeddings.append(embedarr)\n",
    "    index = i\n",
    "    if index % 50 == 0:\n",
    "        clear_output(wait=True)\n",
    "    if index % 1000 == 0:\n",
    "     with open(\"allembeddings.pkl\", \"wb\") as f:\n",
    "        pickle.dump(allembeddings,f)\n",
    "        print(\"Saved a backup\")\n",
    "   except:\n",
    "    errors.append(i)\n",
    "    print(f\"Error in index {i}\")\n",
    "    \n",
    " return allembeddings, errors\n",
    "\n",
    "def flatten(allembeddings):\n",
    " flatlist = []\n",
    " for l in allembeddings:\n",
    "    for e in l:\n",
    "        flatlist.append(e.values)\n",
    " return flatlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9942ff1a-77c6-4bdf-a401-0bf578de3a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114305\n",
      "114310\n",
      "114315\n",
      "114320\n",
      "114325\n",
      "114330\n",
      "114335\n",
      "114340\n",
      "114345\n",
      "114350\n"
     ]
    }
   ],
   "source": [
    "embs,errors = gen_embeddings(promptlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d743ee0-0cc1-405f-943c-59427b928abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "emblist = flatten(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da18ce3e-29a5-422e-a1c8-5f96d7c5bd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114350"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b364c15-7d17-4930-8ebd-877565be681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_emb_csv(medf, csvfname):\n",
    " with open(csvfname, \"w\") as f:\n",
    "    for i in range(medf.embeddings.size):\n",
    "        f.write( str(i) + ',')\n",
    "        f.write( \",\".join(str(medf.embeddings[i])[1:-1].split(\",\")))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db0c3c2b-c9d8-4302-ab2f-9f767d03ca41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings</th>\n",
       "      <th>promptlist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.022194404155015945, 0.012218287214636803, 0...</td>\n",
       "      <td>**&lt;https://s.mj.run/Wi_J4gq275A&gt; guy fawkes ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.01536139938980341, -0.026366332545876503, ...</td>\n",
       "      <td>**an abstract print of 3 brown and white caval...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.036830682307481766, 0.011287277564406395, 0...</td>\n",
       "      <td>**guy fawkes mask, Victo Ngai art nouveau, --a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.006090594921261072, -0.004152672830969095,...</td>\n",
       "      <td>**an abstract etched print of 3 brown and whit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.042925961315631866, -0.03103814460337162, ...</td>\n",
       "      <td>**&lt;https://s.mj.run/m4zXQ5v3ZCo&gt; medieval fort...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          embeddings  \\\n",
       "0  [0.022194404155015945, 0.012218287214636803, 0...   \n",
       "1  [-0.01536139938980341, -0.026366332545876503, ...   \n",
       "2  [0.036830682307481766, 0.011287277564406395, 0...   \n",
       "3  [-0.006090594921261072, -0.004152672830969095,...   \n",
       "4  [-0.042925961315631866, -0.03103814460337162, ...   \n",
       "\n",
       "                                          promptlist  \n",
       "0  **<https://s.mj.run/Wi_J4gq275A> guy fawkes ma...  \n",
       "1  **an abstract print of 3 brown and white caval...  \n",
       "2  **guy fawkes mask, Victo Ngai art nouveau, --a...  \n",
       "3  **an abstract etched print of 3 brown and whit...  \n",
       "4  **<https://s.mj.run/m4zXQ5v3ZCo> medieval fort...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medf = pd.DataFrame()\n",
    "medf['embeddings'] = emblist\n",
    "medf['promptlist'] = promptlist\n",
    "medf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "56c427a2-7d56-4f0f-b5c8-a942a664d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_emb_csv(medf,\"114k_PALM_Embedding.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1fde826c-f567-425b-93fd-ebeca8db6239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://114k_PALM_Embedding.csv [Content-Type=text/csv]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "| [1 files][  1.8 GiB/  1.8 GiB]   54.7 MiB/s                                   \n",
      "Operation completed over 1 objects/1.8 GiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp 114k_PALM_Embedding.csv gs://vertex-gen-ai/mjembedding/text/palm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535f71db-dd3b-477c-b68a-752f646e4bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m102"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
